#!/usr/bin/python3
from datetime import datetime, time
from operator import itemgetter
import os
import sys
import json
import argparse
import subprocess as sp
import matplotlib.pyplot as plt
import matplotlib.offsetbox as offsetbox
import numpy as np
import math
import pandas as pd
import csv

def workload_info(workload):
    if workload.lower() == 'empty-tag':
        return 'only the empty tag'
    elif workload.lower() == 'one-tag-only':
        return 'always the same tag'
    elif workload.lower() == 'new-tags-always':
        return 'always a new tag'
    elif workload.lower() == 'mix':
        return 'mixed workload'

def discard_csv_files(directory, ts, before = True):
    csv_file_names = [file for file in os.listdir(directory) if file.endswith('.csv')]
    csv_files_to_discard = []
    for csv_file_name in csv_file_names:
        chunks = csv_file_name.split('.')[0].split('-')
        ts_file = int(chunks[3])
        if before:
            if ts_file < ts:
                csv_files_to_discard.append(os.path.join(directory, csv_file_name))
        else:
            if ts < ts_file:
                csv_files_to_discard.append(os.path.join(directory, csv_file_name))
    s = "before"
    if not before:
        s = "after"
    print("Remove {} files because they are {} {}".format(len(csv_files_to_discard), s, str(ts)))
    for csv_file in csv_files_to_discard:
        os.remove(csv_file)

def discard_csv_entries(csv_file, ts, before = True):
    df = pd.read_csv(csv_file)
    if before:
        df.drop(df[df.ts_absolute < ts].index, inplace=True)
    else:
        df.drop(df[ts < df.ts_absolute].index, inplace=True)
    df.to_csv((csv_file), mode='w', sep=',', index=False, header=True)

def merge_csv_files(directory, filter, result_file):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    print("Merge {}".format(', '.join(csv_files)))
    combined_csv = pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files])
    combined_csv.to_csv(result_file, index=False)

def concatenate(directory, csv_file_names, filter, result_file):
    csv_files = [os.path.join(directory, file) for file in csv_file_names if filter in file]
    with open(result_file, 'w') as f:
        for csv_file in csv_files:
            with open(csv_file) as f_in:
                for line in f_in:
                    f.write(line)

def count_csv_entries(csv_files):
    return pd.concat([pd.read_csv(file) for file in csv_files]).shape[0]

def count_csv_entries_in_directory(directory, filter):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    print("Count entries of {}".format(', '.join(csv_files)))
    return pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files]).shape[0]

def compute_csv_percentile(csv_file, column_ix, percentile):
    return pd.read_csv(csv_file).iloc[:, column_ix].quantile(q=percentile)

def add_row(directory, latency_append_file, slog, interval, result_file):
    # Get the corrsponding csv files for reads and index memory
    assert 'append' in latency_append_file
    latency_append_file_name = os.path.basename(latency_append_file)
    name_chunks = latency_append_file_name.split('.')[0].split('-') # latencies-append-NODE_ID-TS.csv
    latency_read_file = os.path.join(directory, "latencies-read-{}-{}.csv".format(name_chunks[2], name_chunks[3]))
    index_memory_file = os.path.join(directory, "index-memory-{}-{}.csv".format(name_chunks[2], name_chunks[3]))
    if not os.path.isfile(latency_read_file):
        raise Exception("csv file {} not exists".format(latency_read_file))
    if not os.path.isfile(index_memory_file):
        raise Exception("csv file {} not exists".format(index_memory_file))
    absolute_ts = int(name_chunks[3])
    index_memory = 0
    with open(index_memory_file, newline='') as f:
        index_memory = int(next(csv.reader(f))[0]) 
    # Write to result file
    write_header = not os.path.exists(result_file)
    print("Add row for slog={}, ts={}".format(slog, absolute_ts))
    with open(result_file, 'a', encoding='UTF8', newline='') as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(['slog', 'ts_absolute', 'throughput', 'throughput_append', 'throughput_read', 'latency_append_50','latency_append_99', 'latency_read_50','latency_read_99','index_memory'])
        data = [
            slog,
            absolute_ts,
            round(count_csv_entries([latency_append_file, latency_read_file]) / interval / 1000, 2),
            round(count_csv_entries([latency_append_file]) / interval / 1000, 2),
            round(count_csv_entries([latency_read_file]) / interval / 1000, 2),
            int(compute_csv_percentile(latency_append_file, 0, 0.5)),
            int(compute_csv_percentile(latency_append_file, 0, 0.99)),
            int(compute_csv_percentile(latency_read_file, 0, 0.5)),
            int(compute_csv_percentile(latency_read_file, 0, 0.99)),
            index_memory
        ]
        writer.writerow(data)

def add_rows(directory, slog, interval, result_file):
    latency_append_files = sorted([os.path.join(directory, csv_file_name) for csv_file_name in os.listdir(directory) if 'combined-latencies-append' in csv_file_name])
    for latency_append_file in latency_append_files:
        print(latency_append_file)
        latency_append_file_name = os.path.basename(latency_append_file)
        name_chunks = latency_append_file_name.split('.')[0].split('-') # latencies-append-NODE_ID-TS.csv
        latency_read_file = os.path.join(directory, "combined-latencies-read-{}.csv".format(name_chunks[3]))
        if not os.path.isfile(latency_read_file):
            raise Exception("csv file {} not exists".format(latency_read_file))
        absolute_ts = int(name_chunks[3])
        # Write to result file
        write_header = not os.path.exists(result_file)
        print("Add row for slog={}, ts={}".format(slog, absolute_ts))
        with open(result_file, 'a', encoding='UTF8', newline='') as f:
            writer = csv.writer(f)
            if write_header:
                writer.writerow(['slog', 'ts_absolute', 'throughput', 'latency_append_50','latency_append_99', 'latency_read_50','latency_read_99'])
            data = [
                slog,
                absolute_ts,
                round(count_csv_entries([latency_append_file, latency_read_file]) / interval / 1000, 2),
                int(compute_csv_percentile(latency_append_file, 0, 0.5)),
                int(compute_csv_percentile(latency_append_file, 0, 0.99)),
                int(compute_csv_percentile(latency_read_file, 0, 0.5)),
                int(compute_csv_percentile(latency_read_file, 0, 0.99))
            ]
            writer.writerow(data)

def combine_csv_files_filtered(directory, csv_file_names, engine_ids):
    ts_matrix = []
    num_ts_per_engine = 0
    print("Engine ids:")
    print(engine_ids)
    for id in engine_ids:
        engine_id_csv_files = [file for file in csv_file_names if '-{}-'.format(id) in file]
        ts_of_csv_files = [file.split('.')[0].split('-')[3] for file in engine_id_csv_files]
        ts_matrix.append((id, sorted(ts_of_csv_files)))
        if num_ts_per_engine != 0 and num_ts_per_engine != len(ts_of_csv_files):
            print("Warning: All engines should have the same number of csv files")
        num_ts_per_engine = max(num_ts_per_engine, len(ts_of_csv_files))

    for i in range(num_ts_per_engine):
        related_csv_file_names = []
        for ts_row in ts_matrix:
            id, ts_list = ts_row
            if i < len(ts_list):
                ts = ts_list[i]
                related_csv_file_names.extend([file for file in csv_file_names if '-{}-{}'.format(id, ts) in file])

        id, ts_list = ts_matrix[0]
        ts = ts_list[i]
        for op in ["append", "read"]:
            combined_result_file = os.path.join(directory, "combined-latencies-{}-{}.csv".format(op, ts))
            # now we concatenate the csv files that belong together
            concatenate(directory, related_csv_file_names, op, combined_result_file)

def combine_csv_files(directory, slog, interval, result_file):
    csv_file_names = sorted([file for file in os.listdir(directory) if file.endswith('.csv')])
    
    engine_ids = set()
    filtered_csv_file_names = []
    for csv_file_name in csv_file_names:
        chunks = csv_file_name.split('.')[0].split('-')
        ts = int(chunks[3])
        filtered_csv_file_names.append(csv_file_name)
        engine_ids.add(int(chunks[2]))
    engine_ids = sorted(engine_ids)
    combine_csv_files_filtered(directory, filtered_csv_file_names, engine_ids)

    add_rows(directory, slog, interval, result_file)

def add_column(csv_file, loc, column_name, value):
    print('Add column {}'.format(column_name))
    df = pd.read_csv(csv_file)
    df.insert(loc, column_name, value)
    df.to_csv(csv_file, mode='w', sep=',', index=False, header=True)

def update_column_by_division(csv_file, column, divisor, round_decimals):
    df = pd.read_csv(csv_file)
    for i in df.index:
        df.at[i, column] = round(df.iloc[i][column] / divisor, round_decimals)
    df.to_csv(csv_file, mode='w', sep=',', index=False, header=True)

def make_time_relative(csv_file, reference_ts, csv_result_file):
    print('Make time relative {}'.format(csv_file))
    df = pd.read_csv(csv_file)
    df.drop(df[df.ts_absolute < reference_ts].index, inplace=True)
    relative_timestamps = []
    for i in range(len(df)):
        relative_timestamps.append(df.iloc[i]['ts_absolute'] - reference_ts)
    df.insert(2, 'ts_relative', relative_timestamps)
    write_header = not os.path.isfile(csv_result_file)
    df.to_csv(csv_result_file, mode='a', sep=',', index=False, header=write_header)

# def make_time_relative_all(directory, reference_ts, result_directory):
#     csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]
#     for csv_file in csv_files:
#         make_time_relative(os.path.join(directory, csv_file), reference_ts, result_directory)

def generate_plot_time_vs_throughput(csv_file, result_file):
    df = pd.read_csv(csv_file)

    df_boki = df.loc[df['slog'] == 'boki-local']
    df_boki_hybrid = df.loc[df['slog'] == 'boki-hybrid']
    df_indilog = df.loc[df['slog'] == 'indilog-local']

    plt.plot(df_boki['ts_relative'], df_boki['throughput'], '-', color='royalblue', label='Boki-Complete Throughput')
    plt.plot(df_boki_hybrid['ts_relative'], df_boki_hybrid['throughput'], '-', color='slategrey', label='Boki-Hybrid Throughput')
    plt.plot(df_indilog['ts_relative'], df_indilog['throughput'], '-', color='darkgreen', label='Indilog Throughput')

    plt.xlabel('Time (s)', fontsize=12)
    plt.ylabel('Throughput (kOp/s)', fontsize=12)

    throughput_max = df['throughput'].max()

    plt.ylim(bottom=0, top=throughput_max+50)

    plt.legend()

    plt.savefig(result_file, bbox_inches='tight')
    plt.close

def generate_plot_time_vs_latency_append(csv_file, workload, result_file):
    df = pd.read_csv(csv_file)

    df_boki = df.loc[df['slog'] == 'boki-local']
    df_boki_remote = df.loc[df['slog'] == 'boki-remote']
    df_boki_hybrid = df.loc[df['slog'] == 'boki-hybrid']
    df_indilog = df.loc[df['slog'] == 'indilog-local']
    df_indilog_remote = df.loc[df['slog'] == 'indilog-remote']

    fig, ax = plt.subplots()

    ax.plot(df_boki['ts_relative'], df_boki['latency_append_50'], '--', color='royalblue', label='Boki-Local Append 0,5')
    ax.plot(df_boki['ts_relative'], df_boki['latency_append_99'], '-', color='royalblue', label='Boki-Local Append 0,99')
    
    ax.plot(df_boki_hybrid['ts_relative'], df_boki_hybrid['latency_append_50'], '--', color='darkorange', label='Boki-Hybrid Append 0,5')
    ax.plot(df_boki_hybrid['ts_relative'], df_boki_hybrid['latency_append_99'], '-', color='darkorange', label='Boki-Hybrid Append 0,99')

    ax.plot(df_indilog['ts_relative'], df_indilog['latency_append_50'], '--', color='darkgreen', label='Indilog Append 0,5')
    ax.plot(df_indilog['ts_relative'], df_indilog['latency_append_99'], '-', color='darkgreen', label='Indilog Append 0,99')

    ax.set_ylim(bottom=0)
    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Latency (\u03BCs)')
    ax.set_title('Append latency at engine using {}'.format(workload_info(workload)))

    ax.legend()

    plt.savefig(result_file)
    plt.close

def generate_plot_time_vs_latency_read(csv_file, workload, result_file):
    df = pd.read_csv(csv_file)

    df_boki = df.loc[df['slog'] == 'boki-local']
    df_boki_remote = df.loc[df['slog'] == 'boki-remote']
    df_boki_hybrid = df.loc[df['slog'] == 'boki-hybrid']
    df_indilog = df.loc[df['slog'] == 'indilog-local']
    df_indilog_remote = df.loc[df['slog'] == 'indilog-remote']

    fig, ax = plt.subplots()

    ax.plot(df_boki['ts_relative'], df_boki['latency_read_50'], '--', color='royalblue', label='Boki-Local Read 0,5')
    ax.plot(df_boki['ts_relative'], df_boki['latency_read_99'], '-', color='royalblue', label='Boki-Local Read 0,99')

    ax.plot(df_boki_hybrid['ts_relative'], df_boki_hybrid['latency_read_50'], '--', color='darkorange', label='Boki-Hybrid Read 0,5')
    ax.plot(df_boki_hybrid['ts_relative'], df_boki_hybrid['latency_read_99'], '-', color='darkorange', label='Boki-Hybrid Read 0,99')

    ax.plot(df_indilog['ts_relative'], df_indilog['latency_read_50'], '--', color='darkgreen', label='Indilog Read 0,5')
    ax.plot(df_indilog['ts_relative'], df_indilog['latency_read_99'], '-', color='darkgreen', label='Indilog Read 0,99')

    ax.set_ylim(bottom=0)
    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Latency (\u03BCs)')
    ax.set_title('Read latency at engine using {}'.format(workload_info(workload)))

    ax.legend()

    plt.savefig(result_file)
    plt.close


def generate_plot_time_vs_latency_throughput(directory, workload, result_file):
    latency_index_memory_csv_file = os.path.join(directory, 'time-latency-index-memory.csv')
    cpu_memory_csv_file = os.path.join(directory, 'time-cpu-memory.csv')

    df = pd.read_csv(latency_index_memory_csv_file)
    df_boki = df.loc[df['slog'] == 'boki-local']
    df_boki_remote = df.loc[df['slog'] == 'boki-remote']
    df_indilog = df.loc[df['slog'] == 'indilog-local']
    df_indilog_remote = df.loc[df['slog'] == 'indilog-remote']

    fig, ax = plt.subplots()
    fig.subplots_adjust()

    twin1_tp = ax.twinx()

    p1, = ax.plot(df_boki['ts_relative'], df_boki['latency_append_50'], '--', marker='x', color='blue', label='Boki Append 0,5')
    p2, = ax.plot(df_boki['ts_relative'], df_boki['latency_read_50'], '--', marker='x', color='darkred', label='Boki Read 0,5')
    p3, = ax.plot(df_boki['ts_relative'], df_boki['latency_read_99'], '--', color='darkred', label='Boki Read 0,99')
    p4, = twin1_tp.plot(df_boki['ts_relative'], df_boki['throughput'], '--', color='darkgreen', label='Boki Throughput')
    p5, = ax.plot(df_boki['ts_relative'], df_boki['latency_append_99'], '--', marker='', color='blue', label='Boki Append 0,99')

    # p4, = ax.plot(df_boki_remote['ts_relative'], df_boki_remote['latency_append_50'], '--', marker='x', color='darkred', label='Boki Append 0,5')
    # p5, = ax.plot(df_boki_remote['ts_relative'], df_boki_remote['latency_read_50'], '--', color='darkred', label='Boki Read 0,5')
    # p6, = twin1_tp.plot(df_boki_remote['ts_relative'], df_boki_remote['throughput'], '--', color='darkgreen', label='Boki Throughput')

    p7, = ax.plot(df_indilog['ts_relative'], df_indilog['latency_append_50'], '-', marker='x', color='blue', label='Indilog Append 0,5')
    p8, = ax.plot(df_indilog['ts_relative'], df_indilog['latency_read_50'], '-', marker='x', color='darkred', label='Indilog Read 0,5')
    p9, = ax.plot(df_indilog['ts_relative'], df_indilog['latency_read_99'], '-', color='darkred', label='Indilog Read 0,99')
    p10, = twin1_tp.plot(df_indilog['ts_relative'], df_indilog['throughput'], '-', color='darkgreen', label='Indilog Throughput')
    p11, = ax.plot(df_indilog['ts_relative'], df_indilog['latency_append_99'], '-', marker='', color='blue', label='Indilog Append 0,99')

    # p10, = ax.plot(df_indilog_remote['ts_relative'], df_indilog_remote['latency_append_50'], '-', marker='x', color='darkred', label='Indilog Append 0,5')
    # p11, = ax.plot(df_indilog_remote['ts_relative'], df_indilog_remote['latency_read_50'], '-', color='darkred', label='Indilog Read 0,5')
    # p12, = twin1_tp.plot(df_indilog_remote['ts_relative'], df_indilog_remote['throughput'], '-', color='darkgreen', label='Indilog Throughput')

    twin1_tp.set_ylim(0, 100)

    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Latency (\u03BCs)')
    twin1_tp.set_ylabel('Throughput (kOp/s)')

    ax.yaxis.label.set_color(p1.get_color())
    twin1_tp.yaxis.label.set_color(p3.get_color())

    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.12),
          ncol=6, fancybox=True, shadow=True, handles=[p1, p2, p3, p4, p5, p7, p8, p9, p10, p11],
          prop={'size':5})
    plt.savefig(result_file)
    plt.close

def generate_plot_time_vs_cpu_memory(directory, workload, result_file):
    latency_index_memory_csv_file = os.path.join(directory, 'time-latency-index-memory.csv')
    cpu_memory_csv_file = os.path.join(directory, 'time-cpu-memory.csv')

    df_lim = pd.read_csv(latency_index_memory_csv_file)
    df_lim_boki = df_lim.loc[df_lim['slog'] == 'boki-local']
    df_lim_boki_remote = df_lim.loc[df_lim['slog'] == 'boki-remote']
    df_lim_boki_hybrid = df_lim.loc[df_lim['slog'] == 'boki-hybrid']
    df_lim_indilog = df_lim.loc[df_lim['slog'] == 'indilog-local']
    df_lim_indilog_remote = df_lim.loc[df_lim['slog'] == 'indilog-remote']

    df_cm = pd.read_csv(cpu_memory_csv_file)
    df_cm_boki = df_cm.loc[df_cm['slog'] == 'boki-local']
    df_cm_boki_remote = df_cm.loc[df_cm['slog'] == 'boki-remote']
    df_cm_boki_hybrid = df_cm.loc[df_cm['slog'] == 'boki-hybrid']
    df_cm_indilog = df_cm.loc[df_cm['slog'] == 'indilog-local']
    df_cm_indilog_remote = df_cm.loc[df_cm['slog'] == 'indilog-remote']

    fig, ax1 = plt.subplots()
    fig.subplots_adjust()

    ax2 = ax1.twinx()

    p1, = ax1.plot(df_cm_boki['ts_relative'], df_cm_boki['cpu_avg'], '-', color='royalblue', label='Boki CPU average')
    p2, = ax2.plot(df_lim_boki['ts_relative'], df_lim_boki['index_memory'], '--', color='royalblue', label='Boki Index Memory')

    p5, = ax1.plot(df_cm_indilog['ts_relative'], df_cm_indilog['cpu_avg'], '-', color='darkgreen', label='Indilog CPU average')
    p6, = ax2.plot(df_lim_indilog['ts_relative'], df_lim_indilog['index_memory'], '-', color='darkgreen', label='Indilog Index Memory')

    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('CPU (%)')
    ax2.set_ylabel('Memory (MiB)')

    ax1.set_ylim(bottom=0)
    ax2.set_ylim(bottom=0)

    ax1.yaxis.label.set_color(p1.get_color())
    ax2.yaxis.label.set_color(p2.get_color())

    ax1.set_title('CPU and index memory at engine using {}'.format(workload_info(workload)))

    # ax1.legend(loc='upper center', bbox_to_anchor=(0.5, 1.12),
    #       ncol=6, fancybox=True, shadow=True, handles=[p1, p2, p3, p4],
    #       prop={'size':6})
    #ax1.legend(handles=[p1, p2, p3, p4, p5, p6])
    plt.savefig(result_file)
    plt.close

def generate_plot_time_vs_memory(index_memory_csv_file, cpu_memory_csv_file, result_file):
    df_index_memory = pd.read_csv(index_memory_csv_file)
    df_ram_memory = pd.read_csv(cpu_memory_csv_file)

    df_index_memory_boki = df_index_memory.loc[df_index_memory['slog'] == 'boki-local']
    df_index_memory_boki_hybrid = df_index_memory.loc[df_index_memory['slog'] == 'boki-hybrid']
    df_index_memory_indilog = df_index_memory.loc[df_index_memory['slog'] == 'indilog-local']

    df_ram_memory_boki = df_ram_memory.loc[df_ram_memory['slog'] == 'boki-local']
    df_ram_memory_boki_hybrid = df_ram_memory.loc[df_ram_memory['slog'] == 'boki-hybrid']
    df_ram_memory_indilog = df_ram_memory.loc[df_ram_memory['slog'] == 'indilog-local']

    plt.plot(df_index_memory_boki['ts_relative'], df_index_memory_boki['index_memory'], '--', color='royalblue', label='Boki Complete Index Memory')
    plt.plot(df_ram_memory_boki['ts_relative'], df_ram_memory_boki['mem_tot'], '-', color='royalblue', label='Boki Complete RAM')

    plt.plot(df_index_memory_boki_hybrid['ts_relative'], df_index_memory_boki_hybrid['index_memory'], '--', color='slategrey', label='Boki Hybrid Index Memory')
    plt.plot(df_ram_memory_boki_hybrid['ts_relative'], df_ram_memory_boki_hybrid['mem_tot'], '-', color='slategrey', label='Boki Hybrid RAM')

    plt.plot(df_index_memory_indilog['ts_relative'], df_index_memory_indilog['index_memory'], '--', color='darkgreen', label='Indilog Index Memory')
    plt.plot(df_ram_memory_indilog['ts_relative'], df_ram_memory_indilog['mem_tot'], '-', color='darkgreen', label='Indilog')

    plt.xlabel('Time (s)', fontsize=12)
    plt.ylabel('Memory (MB)', fontsize=12)

    plt.ylim(bottom=0)

    plt.legend()

    plt.savefig(result_file, bbox_inches='tight')
    plt.close

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--directory', type=str)
    parser.add_argument('--file', type=str)
    parser.add_argument('--files', type=str)
    parser.add_argument('--slog', type=str)
    parser.add_argument('--exp-duration', type=int)
    parser.add_argument('--interval', type=int)
    parser.add_argument('--reference-ts', type=int)
    parser.add_argument('--ts', type=int)
    parser.add_argument('--filter', type=str)
    parser.add_argument('--column', type=str)
    parser.add_argument('--divisor', type=int)
    parser.add_argument('--round-decimals', type=int)
    parser.add_argument('--workload', type=str)
    parser.add_argument('--result-file', type=str)
    parser.add_argument('--result-directory', type=str)
    args = parser.parse_args()
    try:
        if args.cmd == 'discard-csv-files-before':
            discard_csv_files(args.directory, args.ts, before=True)
        elif args.cmd == 'discard-csv-files-after':
            discard_csv_files(args.directory, args.ts, before=False) # == after
        elif args.cmd == 'discard-csv-entries-before':
            discard_csv_entries(args.file, args.ts, before=True)
        elif args.cmd == 'discard-csv-entries-after':
            discard_csv_entries(args.file, args.ts, before=False) # == after
        elif args.cmd == 'merge-csv':
            merge_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'add-row':
            add_row(args.directory, args.file, args.slog, args.interval, args.result_file)
        elif args.cmd == 'add-slog-info':
            add_column(args.file, 0, 'slog', args.slog)
        elif args.cmd == 'update-column-by-division':
            update_column_by_division(args.file, args.column, args.divisor, args.round_decimals)
        elif args.cmd == 'combine-csv-files':
            combine_csv_files(args.directory, args.slog, args.interval, args.result_file)
        elif args.cmd == 'make-time-relative':
            make_time_relative(args.file, args.reference_ts, args.result_file)
        elif args.cmd == 'generate-plot-time-vs-latency-append':
            generate_plot_time_vs_latency_append(args.file, args.workload, args.result_file)
        elif args.cmd == 'generate-plot-time-vs-latency-read':
            generate_plot_time_vs_latency_read(args.file, args.workload, args.result_file)
        elif args.cmd == 'generate-plot-time-vs-throughput':
            generate_plot_time_vs_throughput(args.file, args.result_file)
        elif args.cmd == 'generate-plot-time-vs-memory':
            files = args.files.split(',')
            generate_plot_time_vs_memory(files[0], files[1], args.result_file)
        elif args.cmd == 'generate-plot-time-vs-latency-throughput':
            generate_plot_time_vs_latency_throughput(args.directory, args.workload, args.result_file)
        elif args.cmd == 'generate-plot-time-vs-cpu-memory':
            generate_plot_time_vs_cpu_memory(args.directory, args.workload, args.result_file)
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)