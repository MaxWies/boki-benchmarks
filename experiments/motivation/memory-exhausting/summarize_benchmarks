#!/usr/bin/python3
from datetime import datetime, time
from operator import itemgetter
import os
import sys
import json
import argparse
import subprocess as sp
import matplotlib.pyplot as plt
import matplotlib.offsetbox as offsetbox
import numpy as np
import math
import pandas as pd
import csv

def workload_info(workload):
    if workload.lower() == 'empty-tag':
        return 'empty tag'
    elif workload.lower() == 'one-tag-only':
        return 'same tag'
    elif workload.lower() == 'new-tags-always':
        return 'new tag'

def discard_csv_files(directory, ts_end):
    csv_file_names = [file for file in os.listdir(directory) if file.endswith('.csv')]
    csv_files_to_discard = []
    for csv_file_name in csv_file_names:
        chunks = csv_file_name.split('.')[0].split('-')
        ts = int(chunks[3])
        if ts_end < ts:
            csv_files_to_discard.append(os.path.join(directory, csv_file_name))
    for csv_file in csv_files_to_discard:
        os.remove(csv_file)

def discard_csv_entries(csv_file, ts, before = True):
    df = pd.read_csv(csv_file)
    if before:
        df.drop(df[df.ts_absolute < ts].index, inplace=True)
    else:
        df.drop(df[ts < df.ts_absolute].index, inplace=True)
    df.to_csv((csv_file), mode='w', sep=',', index=False, header=True)

def merge_csv_files(directory, filter, result_file):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    print("Merge {}".format(', '.join(csv_files)))
    combined_csv = pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files])
    combined_csv.to_csv(result_file, index=False)

def count_csv_entries(csv_files):
    return pd.concat([pd.read_csv(file) for file in csv_files]).shape[0]

def count_csv_entries_in_directory(directory, filter):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    csv_entries = 0
    for file in csv_files:
        with open(os.path.join(directory, file)) as f:
            for line in f:
                csv_entries += 1
    return csv_entries

def compute_csv_percentile(csv_file, column_ix, percentile):
    return pd.read_csv(csv_file).iloc[:, column_ix].quantile(q=percentile)

def add_row(directory, latency_append_file, slog, interval, result_file):
    # Get the corrsponding csv files for reads and index memory
    assert 'append' in latency_append_file
    latency_append_file_name = os.path.basename(latency_append_file)
    name_chunks = latency_append_file_name.split('.')[0].split('-') # latencies-append-NODE_ID-TS.csv
    latency_read_file = os.path.join(directory, "latencies-read-{}-{}.csv".format(name_chunks[2], name_chunks[3]))
    index_memory_file = os.path.join(directory, "index-memory-{}-{}.csv".format(name_chunks[2], name_chunks[3]))
    if not os.path.isfile(latency_read_file):
        raise Exception("csv file {} not exists".format(latency_read_file))
    if not os.path.isfile(index_memory_file):
        raise Exception("csv file {} not exists".format(index_memory_file))
    absolute_ts = int(name_chunks[3])
    index_memory = 0
    with open(index_memory_file, newline='') as f:
        index_memory = int(next(csv.reader(f))[0]) 
    # Write to result file
    write_header = not os.path.exists(result_file)
    print("Add row for slog={}, ts={}".format(slog, absolute_ts))
    with open(result_file, 'a', encoding='UTF8', newline='') as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(['slog', 'ts_absolute', 'throughput', 'throughput_append', 'throughput_read', 'latency_append_50','latency_append_99', 'latency_read_50','latency_read_99','index_memory'])
        data = [
            slog,
            absolute_ts,
            round(count_csv_entries([latency_append_file, latency_read_file]) / interval / 1000, 2),
            round(count_csv_entries([latency_append_file]) / interval / 1000, 2),
            round(count_csv_entries([latency_read_file]) / interval / 1000, 2),
            int(compute_csv_percentile(latency_append_file, 0, 0.5)),
            int(compute_csv_percentile(latency_append_file, 0, 0.99)),
            int(compute_csv_percentile(latency_read_file, 0, 0.5)),
            int(compute_csv_percentile(latency_read_file, 0, 0.99)),
            index_memory
        ]
        writer.writerow(data)

def add_column(csv_file, loc, column_name, value):
    print('Add column {}'.format(column_name))
    df = pd.read_csv(csv_file)
    df.insert(loc, column_name, value)
    df.to_csv(csv_file, mode='w', sep=',', index=False, header=True)

def update_column_by_division(csv_file, column, divisor, round_decimals):
    df = pd.read_csv(csv_file)
    for i in df.index:
        df.at[i, column] = round(df.iloc[i][column] / divisor, round_decimals)
    df.to_csv(csv_file, mode='w', sep=',', index=False, header=True)

def make_time_relative(csv_file, reference_ts, result_directory):
    print('Make time relative {}'.format(csv_file))
    df = pd.read_csv(csv_file)
    df.drop(df[df.ts_absolute < reference_ts].index, inplace=True)
    print('Dropped lower stuff')
    relative_timestamps = []
    for i in range(len(df)):
        relative_timestamps.append(df.iloc[i]['ts_absolute'] - reference_ts)
    df.insert(2, 'ts_relative', relative_timestamps)
    result_file = os.path.join(result_directory, os.path.basename(csv_file))
    write_header = not os.path.isfile(result_file)
    df.to_csv(os.path.join(result_directory, os.path.basename(csv_file)), mode='a', sep=',', index=False, header=write_header)

def make_time_relative_all(directory, reference_ts, result_directory):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]
    for csv_file in csv_files:
        make_time_relative(os.path.join(directory, csv_file), reference_ts, result_directory)

def generate_plot_time_vs_memory(directory, workload, result_file):
    index_memory_csv_file = os.path.join(directory, 'time-latency-index-memory.csv')
    cpu_memory_csv_file = os.path.join(directory, 'time-cpu-memory.csv')

    df_index_memory = pd.read_csv(index_memory_csv_file)
    df_cpu_memory = pd.read_csv(cpu_memory_csv_file)

    fig, ax1 = plt.subplots()
    fig.subplots_adjust(right=0.87)

    ax2 = ax1.twinx()

    p1, = ax1.plot(df_index_memory['ts_relative'], df_index_memory['index_memory'], '--', color='blue', label='Index Memory')
    p2, = ax2.plot(df_cpu_memory['ts_relative'], df_cpu_memory['mem_tot'], '-', color='darkred', label='RAM of VM')

    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Memory (MB)')
    ax2.set_ylabel('Memory (MB)')

    ax1.set_ylim(bottom=0)
    ax2.set_ylim(bottom=0)

    ax1.yaxis.label.set_color(p1.get_color())
    ax2.yaxis.label.set_color(p2.get_color())

    ax1.legend(handles=[p1, p2])

    plt.title('Memory usage of a Boki engine using {}'.format(workload_info(workload)))
    plt.savefig(result_file)
    plt.close

def generate_plot_all_time_vs_memory(directories, display_title, result_file):
    for directory in directories:
        workload = os.path.basename(directory)

        index_memory_csv_file = os.path.join(directory, 'time-latency-index-memory.csv')
        cpu_memory_csv_file = os.path.join(directory, 'time-cpu-memory.csv')

        df_index_memory = pd.read_csv(index_memory_csv_file)
        df_cpu_memory = pd.read_csv(cpu_memory_csv_file)

        line = 'solid'
        if workload == 'empty-tag':
            line = 'dashed'

        plt.plot(df_index_memory['ts_relative'], df_index_memory['index_memory'], linestyle=line, color='blue', label='Index Memory - {}'.format(workload_info(workload)))
        plt.plot(df_cpu_memory['ts_relative'], df_cpu_memory['mem_tot'], linestyle=line, color='darkred', label='RAM of VM - {}'.format(workload_info(workload)))

    plt.xlabel('Time (s)', fontsize=12)
    plt.ylabel('Memory (MB)', fontsize=12)

    plt.ylim(bottom=0)

    plt.legend()

    if display_title:
        plt.title('Memory usage of a Boki engine')
    plt.savefig(result_file, bbox_inches='tight')
    plt.close

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--directory', type=str)
    parser.add_argument('--file', type=str)
    parser.add_argument('--directories', type=str)
    parser.add_argument('--slog', type=str)
    parser.add_argument('--exp-duration', type=int)
    parser.add_argument('--interval', type=int)
    parser.add_argument('--reference-ts', type=int)
    parser.add_argument('--filter', type=str)
    parser.add_argument('--ts-end', type=int)
    parser.add_argument('--ts', type=int)
    parser.add_argument('--column', type=str)
    parser.add_argument('--divisor', type=int)
    parser.add_argument('--round-decimals', type=int)
    parser.add_argument('--workload', type=str)
    parser.add_argument('--concurrency', type=int)
    parser.add_argument('--display-title', type=str, default='')
    parser.add_argument('--result-file', type=str)
    parser.add_argument('--result-directory', type=str)
    args = parser.parse_args()
    try:
        if args.cmd == 'merge-csv':
            merge_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'discard-csv-files':
            discard_csv_files(args.directory, args.ts_end)
        elif args.cmd == 'discard-csv-entries-before':
            discard_csv_entries(args.file, args.ts, before=True)
        elif args.cmd == 'discard-csv-entries-after':
            discard_csv_entries(args.file, args.ts, before=False) # == after
        elif args.cmd == 'add-row':
            add_row(args.directory, args.file, args.slog, args.interval, args.result_file)
        elif args.cmd == 'add-slog-info':
            add_column(args.file, 0, 'slog', args.slog)
        elif args.cmd == 'update-column-by-division':
            update_column_by_division(args.file, args.column, args.divisor, args.round_decimals)
        elif args.cmd == 'make-time-relative':
            make_time_relative_all(args.directory, args.reference_ts, args.result_directory)
        elif args.cmd == 'generate-plot-time-vs-memory':
            generate_plot_time_vs_memory(args.directory, args.workload, args.result_file)
        elif args.cmd == 'generate-plot-all-time-vs-memory':
            display_title = False
            if args.display_title != "":
                display_title = True
            directories = args.directories.split(',')
            generate_plot_all_time_vs_memory(directories, args.display_title, args.result_file)
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)