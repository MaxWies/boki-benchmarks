#!/usr/bin/python3
from datetime import datetime, time
import os
import sys
import json
import argparse
import matplotlib.pyplot as plt
import numpy as np
import math
import pandas as pd
import csv

def merge_csv_files(directory, filter, result_file):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    combined_csv = pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files])
    combined_csv.to_csv(result_file, index=False)

def concatenate_csv_files(directory, filter, result_file):
    csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    with open(result_file, 'w') as f:
        for csv_file in csv_files:
            with open(csv_file) as f_in:
                for line in f_in:
                    f.write(line)


def count_csv_entries(csv_files):
    return pd.concat([pd.read_csv(file) for file in csv_files]).shape[0]

def count_csv_entries_in_directory(directory, filter):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    # print("Count entries of {}".format(', '.join(csv_files)))
    return pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files]).shape[0]

def compute_csv_percentile(csv_file, column_ix, percentile):
    return pd.read_csv(csv_file).iloc[:, column_ix].quantile(q=percentile)

def compute_df_percentile(df, column_ix, percentile):
    return df.iloc[:, column_ix].quantile(q=percentile)

def compute_df_max(df, column_ix):
    return df.iloc[:, column_ix].max()

def compute_throughput(directory, exp_duration):
    print(round(count_csv_entries_in_directory(directory, '') / exp_duration / 1000, 2))

def get_throughput(throughput_csv_file, slog_config):
    df = pd.read_csv(throughput_csv_file)
    df_config = df.loc[df['slog_config'] == slog_config]
    return df_config['throughput'].iloc[0]

def get_max_latency(directory):
    max_latency = 0
    csv_files = sorted([os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')])
    for csv_file in csv_files:
        max(max_latency, compute_df_max(pd.read_csv(csv_file),0))
    return max_latency

def add_row(slog, slog_config, throughput, read_latency_file, result_file):
    write_header = not os.path.exists(result_file)
    with open(result_file, 'a', encoding='UTF8', newline='') as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow([
                'slog', 'slog_config', 'throughput'
            ])
        data = [
            slog,
            slog_config,
            throughput
        ]
        writer.writerow(data)

def generate_plot(directory, throughput_csv_file, result_file):
    fig, ax = plt.subplots()
    csv_files = sorted([os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')])
    for csv_file in csv_files:
        cdf = []
        latencies = []
        df = pd.read_csv(csv_file)
        df.sort_values(by=df.columns[0])
        for i in range(1,200):
            percentile = round(i/200, 4)
            cdf.append(percentile)
            latency = compute_df_percentile(df, 0, percentile)
            latencies.append(latency)
        csv_file_name = os.path.basename(csv_file)
        slog_config = csv_file_name.split('.')[0].split('_')[1]
        linestyle = '-'
        color = 'g'
        if 'boki-local' in slog_config.lower():
            color = 'royalblue'
        if 'boki-remote' in slog_config.lower():
            color = 'orange'
        if 'notags' in slog_config.lower():
            linestyle = '--'
        ax.plot(latencies, cdf, label='{}, Tp:{}Kop/s'.format(
            slog_config,
            str(get_throughput(throughput_csv_file, slog_config))
        ), linestyle=linestyle, color=color)

    ax.set_xlim(-10, 800)
    ax.set_ylim(0, 1.03)

    x_major_ticks = np.arange(0, 801, 200)
    x_minor_ticks = np.arange(0, 801, 50)
    y_ticks = np.arange(0, 1.1, 0.1)

    ax.set_xticks(x_major_ticks)
    ax.set_xticks(x_minor_ticks, minor=True)
    ax.set_yticks(y_ticks)

    ax.grid(which='both')
    ax.legend()

    plt.xlabel('Latency (\u03BCs)')
    plt.ylabel('Cumulated Latency')

    plt.savefig(result_file)
    plt.close

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--directory', type=str)
    parser.add_argument('--file', type=str)
    parser.add_argument('--slog', type=str)
    parser.add_argument('--slog-config', type=str)
    parser.add_argument('--exp-duration', type=int)
    parser.add_argument('--filter', type=str)
    parser.add_argument('--throughput', type=float)
    parser.add_argument('--is-point-hit', type=str)
    parser.add_argument('--read-latency-file', type=str)
    parser.add_argument('--result-file', type=str)
    args = parser.parse_args()
    try:
        if args.cmd == 'merge-csv':
            merge_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'concatenate-csv':
            concatenate_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'compute-throughput':
            compute_throughput(args.directory, args.exp_duration)
        elif args.cmd == 'add-row':
            add_row(args.slog, args.slog_config, args.throughput, args.read_latency_file, args.result_file)
        elif args.cmd == 'generate-plot':
            generate_plot(args.directory, args.file, args.result_file)
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)