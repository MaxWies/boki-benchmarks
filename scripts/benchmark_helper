#!/usr/bin/python3

import os
import sys
import json
import argparse
import numpy as np
import math
import pandas as pd
import csv

def parse_iftop_bytes_with_unit(amount):
    if 'GB' in amount:
        amount = amount.strip('GB')
        return float(amount)
    if 'MB' in amount:
        amount = amount.strip('MB')
        return float(amount) / 1000
    if 'KB' in amount:
        amount = amount.strip('KB')
        return float(amount) / 1000 ** 2
    if 'B' in amount:
        amount = amount.strip('B')
        return float(amount) / 1000 ** 3 
    print("Unknown amount: {}".format(amount))

def parse_iftop_log(iftop_file, machine_file, exp_duration, result_file):
    gb_sent = 0.0
    gb_received = 0.0
    ips = []
    with open(machine_file) as f:
        config = json.load(f)
        for machine_info in config['machines'].values():
            ips.append(machine_info['ip'])
    lines = open(iftop_file, 'r').readlines()
    for line in lines:
        chunks = line.split()
        for ip in ips:
            if ip in chunks:
                arrow_index = 0
                if '=>' in chunks:
                    arrow_index = chunks.index('=>')
                    cumulative_index = arrow_index + 4
                    gb_sent += parse_iftop_bytes_with_unit(chunks[cumulative_index])
                else:
                    arrow_index = chunks.index('<=')
                    cumulative_index = arrow_index + 4
                    gb_received += parse_iftop_bytes_with_unit(chunks[cumulative_index])

    gb_sent = round(gb_sent, 4)
    gb_received = round(gb_received, 4)

    write_header = not os.path.exists(result_file)
    with open(result_file, 'a', encoding='UTF8', newline='') as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(['gb_sent', 'gb_received', 'mb_per_second_sent', 'mb_per_second_received'])
        data = [
            gb_sent,
            gb_received,
            round(gb_sent * 1000 * 8 / exp_duration, 2),
            round(gb_received * 1000 * 8 / exp_duration, 2),
        ]
        writer.writerow(data)


def workload_info(workload):
    if workload.lower() == 'empty-tag':
        return 'only the empty tag'
    elif workload.lower() == 'one-tag-only':
        return 'always the same tag'
    elif workload.lower() == 'new-tags-always':
        return 'always a new tag'

def concatenate_csv_files(directory, filter, result_file):
    csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    with open(result_file, 'w') as f:
        for csv_file in csv_files:
            with open(csv_file) as f_in:
                for line in f_in:
                    f.write(line)

def discard_csv_files(directory, ts_end):
    csv_file_names = [file for file in os.listdir(directory) if file.endswith('.csv')]
    csv_files_to_discard = []
    for csv_file_name in csv_file_names:
        chunks = csv_file_name.split('.')[0].split('-')
        ts = int(chunks[3])
        if ts_end < ts:
            csv_files_to_discard.append(os.path.join(directory, csv_file_name))
    for csv_file in csv_files_to_discard:
        os.remove(csv_file)

def discard_csv_entries(csv_file, ts, before = True):
    df = pd.read_csv(csv_file)
    if before:
        df.drop(df[df.ts_absolute < ts].index, inplace=True)
    else:
        df.drop(df[ts < df.ts_absolute].index, inplace=True)
    df.to_csv((csv_file), mode='w', sep=',', index=False, header=True)

def merge_csv_files(directory, filter, result_file):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    print("Merge {}".format(', '.join(csv_files)))
    combined_csv = pd.concat([pd.read_csv(os.path.join(directory, file)) for file in csv_files])
    combined_csv.to_csv(result_file, index=False)

def count_csv_entries(csv_files):
    return pd.concat([pd.read_csv(file) for file in csv_files]).shape[0]

def count_csv_entries_in_directory(directory, filter):
    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and filter in file]
    csv_entries = 0
    for file in csv_files:
        with open(os.path.join(directory, file)) as f:
            for line in f:
                csv_entries += 1
    return csv_entries

def compute_csv_percentile(csv_file, column_ix, percentile):
    return pd.read_csv(csv_file).iloc[:, column_ix].quantile(q=percentile)

def compute_column_average(csv_file, column):
    print(pd.read_csv(csv_file)[column].mean())

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--directory', type=str)
    parser.add_argument('--file', type=str)
    parser.add_argument('--machine-file', type=str)
    parser.add_argument('--slog', type=str)
    parser.add_argument('--exp-duration', type=int)
    parser.add_argument('--interval', type=int)
    parser.add_argument('--reference-ts', type=int)
    parser.add_argument('--filter', type=str)
    parser.add_argument('--ts-end', type=int)
    parser.add_argument('--ts', type=int)
    parser.add_argument('--column', type=str)
    parser.add_argument('--divisor', type=int)
    parser.add_argument('--round-decimals', type=int)
    parser.add_argument('--workload', type=str)
    parser.add_argument('--result-file', type=str)
    parser.add_argument('--result-directory', type=str)
    args = parser.parse_args()
    try:
        if args.cmd == 'merge-csv':
            merge_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'concatenate-csv':
            concatenate_csv_files(args.directory, args.filter, args.result_file)
        elif args.cmd == 'discard-csv-files':
            discard_csv_files(args.directory, args.ts_end)
        elif args.cmd == 'discard-csv-entries-before':
            discard_csv_entries(args.file, args.ts, before=True)
        elif args.cmd == 'discard-csv-entries-after':
            discard_csv_entries(args.file, args.ts, before=False) # == after
        elif args.cmd == 'add-slog-info':
            add_column(args.file, 0, 'slog', args.slog)
        elif args.cmd == 'compute-column-average':
            compute_column_average(args.file, args.column)
        elif args.cmd == 'parse-iftop-log':
            parse_iftop_log(args.file, args.machine_file, args.exp_duration, args.result_file) 
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)