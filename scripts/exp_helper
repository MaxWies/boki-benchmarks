#!/usr/bin/python3

import os
import sys
import time
import json
from simplejson import load
import yaml
import random
import string
import argparse
import subprocess as sp

AWS_REGION = 'us-east-2'
AMI_ID = 'ami-0c6de836734de3280'
SECURITY_GROUP_NAME = 'boki'
PLACEMENT_GROUP = 'boki-experiments'
AVAILABILITY_ZONE = 'us-east-2a'

# TODO: improve
USER_NAME = 'mrc'

def random_string(length):
    letters = string.ascii_lowercase
    return ''.join(random.choice(letters) for _ in range(length))

def run_aws_command(scope, cmd):
    ret = sp.run(['aws', '--region', AWS_REGION, '--output', 'json', scope] + cmd,
                 stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8', cwd=os.environ['HOME'])
    if ret.returncode != 0:
        raise Exception('Failed to run aws-cli command: ' + ret.stderr)
    result = ret.stdout.strip()
    return json.loads(result) if result != '' else {}

def run_aws_ec2_command(cmd):
    return run_aws_command('ec2', cmd)

def run_remote_command(ssh_ip, cmd):
    ret = sp.run(['ssh', '-q', ssh_ip + '-' + USER_NAME, '--'] + cmd,
                 stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8')
    if ret.returncode != 0:
        raise Exception('Failed to run remote command: ' + ' '.join(cmd) + '\n' + ret.stderr)
    return ret.stdout, ret.stderr

def start_ec2_instance(name, instance_type, security_group_id, instance_role):
    launch_args = [
        '--image-id', AMI_ID,
        '--instance-type', instance_type,
        '--security-group-ids', security_group_id,
        '--placement', 'AvailabilityZone='+AVAILABILITY_ZONE+',GroupName='+PLACEMENT_GROUP,
        '--tag-specifications', 'ResourceType=instance,Tags=[{Key=Name,Value='+name+'}]'
    ]
    if instance_role is not None:
        launch_args.extend(['--iam-instance-profile', 'Arn='+instance_role])
    cli_output = run_aws_ec2_command(['run-instances'] + launch_args)
    instance_info = cli_output['Instances'][0]
    return {
        'instance_id': instance_info['InstanceId'],
        'dns': instance_info['PrivateDnsName'],
        'ip': instance_info['PrivateIpAddress']
    }

def request_ec2_spot_instance(group_id, instance_type, security_group_id, instance_role):
    launch_spec = {
        'ImageId': AMI_ID,
        'InstanceType': instance_type,
        'SecurityGroupIds': [security_group_id],
        'Placement': {
            'AvailabilityZone': AVAILABILITY_ZONE,
            'GroupName': PLACEMENT_GROUP
        }
    }
    if instance_role is not None:
        launch_spec['IamInstanceProfile'] = { 'Arn': instance_role }
    cli_output = run_aws_ec2_command([
        'request-spot-instances', '--type', 'one-time',
        '--availability-zone-group', group_id, '--launch-group', group_id,
        '--launch-specification', json.dumps(launch_spec)])
    return cli_output['SpotInstanceRequests'][0]['SpotInstanceRequestId']

def cancel_spot_instance_requests(spot_requests):
    request_ids = list(spot_requests.values())
    for request_id in request_ids:
        request_status = run_aws_ec2_command(
            ['describe-spot-instance-requests',
             '--spot-instance-request-ids', request_id])
        request_status = request_status['SpotInstanceRequests'][0]
        if 'InstanceId' in request_status:
            run_aws_ec2_command(['terminate-instances', '--instance-ids',
                                 request_status['InstanceId']])
        run_aws_ec2_command(['cancel-spot-instance-requests',
                             '--spot-instance-request-ids', request_id])

def find_security_group_id():
    cli_output = run_aws_ec2_command([
        'describe-security-groups',
        '--filters', 'Name=group-name,Values='+SECURITY_GROUP_NAME])
    if len(cli_output['SecurityGroups']) == 0:
        raise Exception('Failed to find security group %s' % SECURITY_GROUP_NAME)
    return cli_output['SecurityGroups'][0]['GroupId']

def find_instance_role(role_name):
    cli_output = run_aws_command('iam', ['get-instance-profile', '--instance-profile-name', role_name])
    return cli_output['InstanceProfile']['Arn']

def start_spot_instances(machine_configs, waiting_time, instance_role):
    security_group_id = find_security_group_id()
    spot_requests = {}
    group_id = random_string(10)
    results = {}
    try:
        for name, config in machine_configs.items():
            spot_requests[name] = request_ec2_spot_instance(
                group_id, config['type'], security_group_id, instance_role)
        time.sleep(waiting_time)
        for name, config in machine_configs.items():
            request_status = run_aws_ec2_command(
                ['describe-spot-instance-requests',
                 '--spot-instance-request-ids', spot_requests[name]])
            request_status = request_status['SpotInstanceRequests'][0]
            if request_status['Status']['Code'] != 'fulfilled':
                raise Exception(
                    'Spot request for %s is not fulfilled after %d seconds' % (name, waiting_time))
            instance_id = request_status['InstanceId']
            instance_info = run_aws_ec2_command(
                ['describe-instances', '--instance-ids', instance_id])
            instance_info = instance_info['Reservations'][0]['Instances'][0]
            results[name] = {
                'instance_id': instance_id,
                'dns': instance_info['PrivateDnsName'],
                'ip': instance_info['PrivateIpAddress'],
                'role': config['role']
            }
            if 'labels' in config:
                results[name]['labels'] = config['labels']
            run_aws_ec2_command(
                ['create-tags', '--resources', instance_id, '--tags', 'Key=Name,Value='+name])
    except Exception as e:
        cancel_spot_instance_requests(spot_requests)
        raise e
    return results

def setup_hostname_for_machines(machine_configs):
    for name, machine_config in machine_configs.items():
        if machine_config['role'] != 'dirigent':
            run_remote_command(machine_config['ip'], ['sudo', 'hostnamectl', 'set-hostname', name])

def setup_instance_storage(machine_configs):
    for name, machine_config in machine_configs.items():
        if 'mount_instance_storage' in machine_config:
            ip = machine_configs[name]['ip']
            device = '/dev/' + machine_config['mount_instance_storage']
            run_remote_command(ip, ['sudo', 'mkfs', '-t', 'ext4', device])
            run_remote_command(ip, ['sudo', 'mkdir', '/mnt/storage'])
            run_remote_command(ip, ['sudo', 'mount', '-o', 'defaults,noatime', device, '/mnt/storage'])

def setup_docker_swarm_for_machines(machine_configs):
    manager_machine = None
    for name, machine_config in machine_configs.items():
        if machine_config['role'] == 'manager':
            if manager_machine is not None:
                raise Exception('More than one manager machine')
            run_remote_command(
                machine_config['ip'],
                ['docker', 'swarm', 'init', '--advertise-addr', machine_config['ip']])
            time.sleep(10)
            manager_machine = name
            join_token, _ = run_remote_command(
                machine_config['ip'],
                ['docker', 'swarm', 'join-token', '-q', 'worker'])
            join_token = join_token.strip()
    if manager_machine is None:
        raise Exception('No manager machine')
    for name, machine_config in machine_configs.items():
        if machine_config['role'] == 'worker':
            run_remote_command(
                machine_config['ip'],
                ['docker', 'swarm', 'join', '--token', join_token,
                 machine_configs[manager_machine]['ip']+':2377'])
    time.sleep(10)
    for name, machine_config in machine_configs.items():
        if 'labels' in machine_config:
            cmd = ['docker', 'node', 'update']
            for label_str in machine_config['labels']:
                cmd.extend(['--label-add', label_str])
            cmd.append(name)
            run_remote_command(machine_configs[manager_machine]['ip'], cmd)

def start_machines_main(base_dir):
    machine_config_file = 'config.json'
    if not os.path.exists(os.path.join(base_dir, machine_config_file)):
        raise Exception('Could not find file {}!'.format(machine_config_file))
    with open(os.path.join(base_dir, machine_config_file)) as fin:
        config = json.load(fin)
    try:
        start_time = time.time()
        #setup_hostname_for_machines(config['machines'])
        setup_instance_storage(config['machines'])
        setup_docker_swarm_for_machines(config['machines'])
        elapsed = time.time() - start_time
        print('Finish setup in %.3f seconds' % (elapsed,))
    except Exception as e:
        raise e

def generate_docker_compose_main(base_dir):
    config = load_config_file(base_dir)
    docker_compose = { 'version': '3.8', 'services': {} }
    for name, service_config in config['services'].items():
        docker_compose['services'][name] = { 'deploy': {} }
        service_docker_compose = docker_compose['services'][name]
        service_docker_compose['deploy']['replicas'] = service_config.get('replicas', 1)
        if 'placement' in service_config:
            service_docker_compose['deploy']['placement'] = {
                'constraints': ['node.hostname == %s' % (service_config['placement'],)]
            }
        elif 'placement_label' in service_config:
            service_docker_compose['deploy']['placement'] = {
                'constraints': ['node.labels.%s == true' % (service_config['placement_label'],)],
                'max_replicas_per_node': 1
            }
        service_docker_compose['environment'] = []
        service_docker_compose['volumes'] = []
        if 'need_aws_env' in service_config and service_config['need_aws_env']:
            if 'aws_access_key_id' in config:
                service_docker_compose['environment'].append(
                    'AWS_ACCESS_KEY_ID=%s' % (config['aws_access_key_id'],))
            if 'aws_secret_access_key' in config:
                service_docker_compose['environment'].append(
                    'AWS_SECRET_ACCESS_KEY=%s' % (config['aws_secret_access_key'],))
            if 'aws_region' in config:
                service_docker_compose['environment'].append(
                    'AWS_REGION=%s' % (config['aws_region'],))
        if 'mount_certs' in service_config and service_config['mount_certs']:
            service_docker_compose['volumes'].append(
                '/etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt')
    with open(os.path.join(base_dir, 'docker-compose-generated.yml'), 'w') as fout:
        yaml.dump(docker_compose, fout, default_flow_style=False)

def load_config_file(base_dir):
    config_file = 'config.json'
    if not os.path.exists(os.path.join(base_dir, config_file)):
        raise Exception('Could not find file {}!'.format(config_file))
    with open(os.path.join(base_dir, config_file)) as fin:
        config = json.load(fin)
    return config

def get_host_main(base_dir, machine_name):
    print(load_config_file(base_dir)['machines'][machine_name]['ip'])

def get_service_host_main(base_dir, service_name):
    config = load_config_file(base_dir)
    machine = config['services'][service_name]['placement']
    print(config[machine]['ip'])

def get_docker_manager_host_main(base_dir):
    for machine_info in load_config_file(base_dir)['machines'].values():
        if machine_info['role'] == 'manager':
            print(machine_info['ip'])
            break
    
def get_client_host_main(base_dir):
    for machine_info in load_config_file(base_dir)['machines'].values():
        if machine_info['role'] == 'client':
            print(machine_info['ip'])
            break

def get_all_server_hosts_main(base_dir):
    for machine_info in load_config_file(base_dir)['machines'].values():
        if machine_info['role'] != 'client':
            print(machine_info['ip'])

def get_machine_with_label_main(base_dir, label):
    for machine_info in load_config_file(base_dir)['machines'].values():
        if 'labels' in machine_info:
            labels = machine_info['labels']
            if label in labels or label+'=true' in labels:
                print(machine_info['ip'])

def get_container_id_main(base_dir, service_name, machine_name, machine_host):
    machine_infos = load_config_file(base_dir)['machines'].values()    
    if machine_host is None:
        if machine_name is None:
            machine_name = load_config_file(base_dir)['services'][service_name]['placement']
        machine_host = machine_infos[machine_name]['dns']
    short_id, _ = run_remote_command(machine_host,
                                     ['docker', 'ps', '-q', '-f', 'name='+service_name])
    short_id = short_id.strip()
    if short_id != '':
        container_info, _ = run_remote_command(machine_host, ['docker', 'inspect', short_id])
        container_info = json.loads(container_info)[0]
        print(container_info['Id'])

def collect_container_logs_main(base_dir, log_path):
    for machine_info in load_config_file(base_dir)['machines'].values():
        if machine_info['role'] == 'client':
            continue
        container_ids, _ = run_remote_command(machine_info['ip'], ['docker', 'ps', '-q'])
        container_ids = container_ids.strip().split()
        for container_id in container_ids:
            container_info, _ = run_remote_command(
                machine_info['ip'], ['docker', 'inspect', container_id])
            container_info = json.loads(container_info)[0]
            container_name = container_info['Name'][1:]  # remove prefix '/'
            log_stdout, log_stderr = run_remote_command(
                machine_info['ip'], ['docker', 'container', 'logs', container_id])
            with open(os.path.join(log_path, '%s.stdout' % container_name), 'w') as fout:
                fout.write(log_stdout)
            with open(os.path.join(log_path, '%s.stderr' % container_name), 'w') as fout:
                fout.write(log_stderr)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--base-dir', type=str, default='.')
    parser.add_argument('--machine-name', type=str, default=None)
    parser.add_argument('--machine-label', type=str, default=None)
    parser.add_argument('--machine-host', type=str, default=None)
    parser.add_argument('--service', type=str, default=None)
    parser.add_argument('--log-path', type=str, default=None)
    args = parser.parse_args()
    try:
        if args.cmd == 'start-machines':
            start_machines_main(args.base_dir)
        # elif args.cmd == 'stop-machines':
        #     stop_machines_main(args.base_dir)
        elif args.cmd == 'generate-docker-compose':
            generate_docker_compose_main(args.base_dir)
        elif args.cmd == 'get-host':
            get_host_main(args.base_dir, args.machine_name)
        elif args.cmd == 'get-service-host':
            get_service_host_main(args.base_dir, args.service)
        elif args.cmd == 'get-docker-manager-host':
            get_docker_manager_host_main(args.base_dir)
        elif args.cmd == 'get-client-host':
            get_client_host_main(args.base_dir)
        elif args.cmd == 'get-all-server-hosts':
            get_all_server_hosts_main(args.base_dir)
        elif args.cmd == 'get-machine-with-label':
            get_machine_with_label_main(args.base_dir, args.machine_label)
        elif args.cmd == 'get-container-id':
            get_container_id_main(args.base_dir, args.service, args.machine_name, args.machine_host)
        elif args.cmd == 'collect-container-logs':
            collect_container_logs_main(args.base_dir, args.log_path)
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)
