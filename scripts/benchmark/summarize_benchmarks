#!/usr/bin/python3
from datetime import datetime, time
import os
import sys
import json
import argparse
import subprocess as sp

# TODO: improve
USER_NAME = 'mrc'

def run_remote_command(ssh_ip, cmd):
    print(cmd, file=sys.stderr)
    ret = sp.run(['ssh', '-q', ssh_ip + '-' + USER_NAME, '--'] + cmd,
                 stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8')
    if ret.returncode != 0:
        raise Exception('Failed to run remote command: ' + ' '.join(cmd) + '\n' + ret.stderr)
    return ret.stdout, ret.stderr

def compute_bucket_percentile(bucket, number_of_entries, percentile):
    bucket_slot_index = 0
    threshold = percentile * number_of_entries
    entries_visited = bucket["slots"][bucket_slot_index]
    while entries_visited < threshold:
        bucket_slot_index += 1
        entries_visited += bucket["slots"][bucket_slot_index]
    return bucket["lower"] + bucket_slot_index * bucket["interval"]

def unix_timestamp_to_datetime(unix_timestamp_nanosec):
    dt = datetime.utcfromtimestamp(unix_timestamp_nanosec // 1000000000)
    nanosec = (unix_timestamp_nanosec - (unix_timestamp_nanosec // 1000000000) * 1000000000)
    microsec = nanosec // 1000
    return dt.strftime('%Y-%m-%d %H:%M:%S') + ' {}'.format(microsec)

def make_timestamps_human_readable(dic, key_matcher):
    for key in dic.keys():
        if key_matcher in key:
            dic[key] = unix_timestamp_to_datetime(dic[key])

def show_benchmark_results(result_file):
    pretty_benchmark = None
    with open(result_file) as f:
        benchmark = json.load(f)
        for operation in benchmark["operations"]:
            e = sum(operation["bucket"]["slots"])
            print("Successful calls {}. Bucket entries {}".format(operation["calls_success"], e))
            if "bucket" in operation:
                operation["latency_p10"] = compute_bucket_percentile(operation["bucket"], e, 0.10)
                operation["latency_p50"] = compute_bucket_percentile(operation["bucket"], e, 0.5)
                operation["latency_p75"] = compute_bucket_percentile(operation["bucket"], e, 0.75)
                operation["latency_p90"] = compute_bucket_percentile(operation["bucket"], e, 0.90)
                operation["latency_p99"] = compute_bucket_percentile(operation["bucket"], e, 0.99)
                operation["latency_p99.9"] = compute_bucket_percentile(operation["bucket"], e, 0.999)
                del operation["bucket"]
            if "latency_head" in operation:
                operation["latency_min"] = min(operation["latency_head"]["items"])
            if "latency_tail" in operation:
                operation["latency_max"] = max(operation["latency_tail"]["items"])
        if "time_log" in benchmark:
            make_timestamps_human_readable(benchmark["time_log"], 'time')
        pretty_benchmark = json.dumps(benchmark, sort_keys=True, indent=4)
    if pretty_benchmark is None:
        raise Exception
    with open(os.path.join(os.path.dirname(result_file), os.path.basename(result_file)), 'w') as f:
        f.write(pretty_benchmark)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--result-file', type=str)
    args = parser.parse_args()
    try:
        show_benchmark_results(args.result_file)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)

#show_benchmark_results('test.json')